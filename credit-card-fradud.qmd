---
title: "Proyecto deteccion de fraude en tarjeta de credito"
author: "Leandro Soto Miranda"
date: "2024-10-24"
format: 
  html: 
    toc: true 
    code-fold: true
---

## 1. Definir problema

- En este proyecto, analizaremos un conjunto de datos relacionaciodnado con la productividad

## 2. Recopilación de datos

```{python}
# Importación de librerías
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.ensemble import StackingRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
import warnings
warnings.filterwarnings('ignore', category=FutureWarning)

    
# Carga de datos
df = pd.read_csv('data.csv', sep=",")

# Resumen estadístico
# Mostrar las primeras filas del dataset
print("Primeras filas del dataset:")
print(df.head())

# Mostrar información general del dataset
print("\nInformación del dataset:")
print(df.info())

# Descripción estadística básica del dataset
print("\nDescripción estadística:")
print(df.describe())

info = df.shape
print("\nLa cantidad de filas y columnas en nuestro dataframe es de:",info)

tipos = df.dtypes
print("\nTipos de datos presentes en el dataset:\n",tipos)
```

## 3. Análisis de datos por Variable
## Análisis de datos cuantitativos

```{python}
# Función para el análisis univariado de variables cuantitativas
def analizar_variable_cuantitativa(df, columna):
    mean = np.mean(df[columna])
    median = np.median(df[columna])
    std = np.std(df[columna])
    min_value = np.min(df[columna])
    max_value = np.max(df[columna])

    print(f"Análisis de la Variable '{columna}'")
    print(f"Media: {mean:.2f}")
    print(f"Mediana: {median:.2f}")
    print(f"Desviación Estándar: {std:.2f}")
    print(f"Valor Mínimo: {min_value:.2f}")
    print(f"Valor Máximo: {max_value:.2f}")
    print("\n")

    # Visualización de la distribución (Histograma con KDE)
    plt.figure(figsize=(10, 6))
    sns.histplot(df[columna], bins=30, kde=True, color='#4C72B0')
    plt.title(f'Distribución de {columna}')
    plt.xlabel(columna)
    plt.ylabel('Frecuencia')
    plt.show()

# Aplicar la función a todas las columnas numéricas del dataframe
columnas_cuantitativas = df.select_dtypes(include=['int64', 'float64']).columns
for columna in columnas_cuantitativas:
    analizar_variable_cuantitativa(df, columna)
```

## Análisis de datos cualitativos

```{python}
# Función para el análisis univariado de variables categóricas
def analizar_variable_categorica(df, columna):
    values_counts = df[columna].value_counts()
    moda = values_counts.idxmax()

    print(f"Análisis Univariado de la Variable '{columna}'")
    print(f"Frecuencia de las categorías:\n{values_counts}")
    print(f"Moda (Categoría más frecuente): {moda}")
    print("\n")

    # Visualización de la distribución
    plt.figure(figsize=(10, 6))
    sns.countplot(
        x=columna, 
        data=df[df[columna].isin(values_counts.index)], 
        order=values_counts.index, 
        palette='Set2'
    )
    plt.title(f'Distribución de {columna}')
    plt.xlabel(columna)
    plt.ylabel('Frecuencia')
    plt.xticks(rotation=45)
    plt.show()

# Columnas categóricas a excluir
columnas_a_excluir = ['TransactionDate']

columnas_categoricas = [col for col in df.select_dtypes(include=['object']).columns if col not in columnas_a_excluir]

for columna in columnas_categoricas:
    analizar_variable_categorica(df, columna)


```

## Verificar si hay patrones o relaciones presentes entre variables

## Verificar si hay valores nulos en el dataset
### Corrección de valores nulos presentes en el dataset
```{python}
print("\nValores nulos por columna:")
print(df.isnull().sum())
```

# Procesamiento de datos
# Verificar si hay valores atípicos
```{python}
def generar_boxplot(df, columna):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=df, x=columna, palette='Set2')
    plt.title(f'Boxplot de {columna}')
    plt.xlabel(columna)
    plt.show()

# Aplicar la función a todas las columnas numéricas del dataframe
columnas_numericas = df.select_dtypes(include=['int64', 'float64']).columns
for columna in columnas_numericas:
    generar_boxplot(df, columna)
```

- Para el tratamiento de datos atípicos lo que vamos a realizar es la imputación de ellos mediante el método intercuartílico, pero también vamos a generar un dataset sin realizar ningún tratamiento de los datos outlayers presentes en el dataset para realizar pruebas posteriormente en la aplicación de modelos de machine learning para ver cuanta diferencia hay entre ambos casos.
```{python}

df_clean = df.copy()

variable_objetivo = 'IsFraud'
df_sin_objetivo = df_clean.drop(columns=[variable_objetivo])

for col in df_sin_objetivo.select_dtypes(include=['int64', 'float64']).columns:
    # Calcula Q1 y Q3
    Q1 = df_sin_objetivo[col].quantile(0.25)
    Q3 = df_sin_objetivo[col].quantile(0.75)
    IQR = Q3 - Q1
    
    # Define los límites inferior y superior
    lower_limit = Q1 - 1.5 * IQR
    upper_limit = Q3 + 1.5 * IQR

    # Imputa los valores atípicos por los límites correspondientes
    df_sin_objetivo[col] = np.where(df_sin_objetivo[col] < lower_limit, lower_limit, df_sin_objetivo[col])
    df_sin_objetivo[col] = np.where(df_sin_objetivo[col] > upper_limit, upper_limit, df_sin_objetivo[col])

# Reinserta la variable objetivo en el DataFrame limpio
df_clean = pd.concat([df_sin_objetivo, df_clean[[variable_objetivo]]], axis=1)

# Verificamos algunos valores antes y después de la limpieza
print("Datos antes de la limpieza:")
print(df.describe())
print("\nDatos después de la limpieza:")
print(df_clean.describe())

```

- Lo que realizamos aqui es explir nuestra varialbe objetivo la cual es IsFraud ya que uno de los principales problemas es que al tenere pocos datos para uno de los valores lo clasificaba como outlayer y a la hora de apklciarldo estos datos se eliminaban, si bien son pocos datos lo que se iban eliminando siguen siendo importantes para la posterior balanceo de datos

## Preparación de datos
### Vamos a realizar el tratamiento de datos pasos a realizar
### Convertir datos categóricos a numéricos para esto vamos a aplicar one hot encoder y label conder dependiendo a tipo de dato
### Además de convertir los datos categóricos en general para aplicar estos datos en modelos de machine learning, además de verificar el balanceo de datos y aplicación de técnicas para corregir variables con outlayers

```{python}
for column in df.columns:
    unique_values = df[column].unique()
    print(f"Valores únicos en la columna '{column}':")
    print(unique_values)
    print("\n------------------------------------\n")
```

## LabelEncoder

### Variables Ninguna

## OneHotEncoder

### Variables: Location, TransactionType
```{python}
# Aplicar One-Hot Encoding
df = pd.get_dummies(df, columns=['Location'])
df = pd.get_dummies(df, columns=['TransactionType'])
# datos sin outlayers
df_clean = pd.get_dummies(df_clean, columns=['Location'])
df_clean = pd.get_dummies(df_clean, columns=['TransactionType'])

```

```{python}
for column in df.columns:
    unique_values = df[column].unique()
    print(f"Valores únicos en la columna '{column}':")
    print(unique_values)
    print("\n------------------------------------\n")
```

### Verificacion sobre el balance de los datos de la variable IsFraud, para posterior tratamiento
- Con esto tenemos un problema, nuestra variable objetivo esta demasiado desbalanceada, po lo que tendremos que aplicar balanceo de datos ya bien sea con oversample (SMOTE) a la variable minoritaria o undersample a nuestra variable mayoritaria
```{python}

variable = 'IsFraud'
balance = df[variable].value_counts(normalize=True) * 100

print(f"Distribución de '{variable}':")
print(balance)

# Visualizar distribución con un gráfico de barras
plt.figure(figsize=(8, 5))
sns.countplot(data=df, x=variable, order=balance.index, palette="viridis")
plt.title(f"Distribución de la variable '{variable}'")
plt.xlabel(variable)
plt.ylabel("Frecuencia")
plt.xticks(rotation=45)
plt.show()

```

### Aplicación de Class Weighting en el Modelo
```{python}

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# Dividir en variables predictoras (X) y la variable objetivo (y)
X = df.drop(columns=["IsFraud", "TransactionDate"])
y = df["IsFraud"]

# Dividir en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Aplicación de class_weight para un modelo (ejemplo con RandomForest)
model_rf = RandomForestClassifier(class_weight="balanced", random_state=42)
model_rf.fit(X_train, y_train)

# Otro ejemplo con Logistic Regression
model_lr = LogisticRegression(class_weight="balanced", random_state=42)
model_lr.fit(X_train, y_train)
```

### Combination of Oversampling (con RandomOverSampler) y Class Weighting

```{python}
from sklearn.utils.class_weight import compute_class_weight
from imblearn.over_sampling import RandomOverSampler
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier

# Crear un oversampler
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)

# Crear un nuevo DataFrame con el dataset balanceado
df_balanced = pd.DataFrame(X_resampled, columns=X.columns)
df_balanced["IsFraud"] = y_resampled

# Calcular class_weight para el modelo
class_weights = compute_class_weight("balanced", classes=np.array([0, 1]), y=y_resampled)
class_weight_dict = {0: class_weights[0], 1: class_weights[1]}

# Modelo con class_weight aplicado
model_balanced_rf = RandomForestClassifier(class_weight=class_weight_dict, random_state=42)
model_balanced_rf.fit(X_resampled, y_resampled)

print("Distribución después del balanceo:")
print(df_balanced["IsFraud"].value_counts())

```

```{python}

variable = 'IsFraud'
balance = df_balanced[variable].value_counts(normalize=True) * 100

print(f"Distribución de '{variable}':")
print(balance)

# Visualizar distribución con un gráfico de barras
plt.figure(figsize=(8, 5))
sns.countplot(data=df_balanced, x=variable, order=balance.index, palette="viridis")
plt.title(f"Distribución de la variable '{variable}'")
plt.xlabel(variable)
plt.ylabel("Frecuencia")
plt.xticks(rotation=45)
plt.show()

```

```{python}
df_balanced

```


```{python}
# Calcular la matriz de correlación
corr_matrix = df_balanced.corr()

# Generar el mapa de calor
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Mapa de calor de la correlación entre variables')
plt.show()
```

```{python}
# Calcular la matriz de correlación
correlation_matrix = df_balanced.corr()

# Filtrar solo las correlaciones con la variable objetivo
target_corr = correlation_matrix['IsFraud'].sort_values(ascending=False)
print("Correlación de cada variable con 'Productivity_Score':\n", target_corr)
```

# Aplicación de modelos de machine learning

## Predicción con datos atípicos

```{python}
# Variables utilizadas
print("Variables utilizadas en el modelo:")
print(X.columns)

```

## Predicción sin datos atípicos
```{python}
from sklearn.model_selection import train_test_split

# Seleccionar características (features) y la variable objetivo (target)
X = df_balanced.drop(columns=['IsFraud'])
y = df_balanced['IsFraud']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```


```{python}
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Crear el modelo de Regresión Logística
model = LogisticRegression()

# Entrenar el modelo
model.fit(X_train, y_train)

# Predecir en los datos de prueba
y_pred = model.predict(X_test)

# Evaluar el modelo
accuracy_RL = accuracy_score(y_test, y_pred)
matrix_RL = confusion_matrix(y_test, y_pred)
reporte_RL = classification_report(y_test, y_pred)

print(f'Precisión del modelo: {accuracy_RL:.2f}')
print('Matriz de confusión:')
print(matrix_RL)
print('Reporte de clasificación:')
print(reporte_RL)

```

```{python}

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import joblib

# Crear el modelo de Árbol de Decisión
model = DecisionTreeClassifier()

# Entrenar el modelo
model.fit(X_train, y_train)

# Predecir en los datos de prueba
y_pred = model.predict(X_test)

# Evaluar el modelo
accuracy_AD = accuracy_score(y_test, y_pred)
matrix_AD = confusion_matrix(y_test, y_pred)
reporte_AD = classification_report(y_test, y_pred)

print(f'Precisión del modelo: {accuracy_AD:.2f}')
print('Matriz de confusión:')
print(matrix_AD)
print('Reporte de clasificación:')
print(reporte_AD)

```
# Conclusiones finales

### Comentarios y Comparación de los Modelos
Modelo Inicial:

- Precisión: 0.52, lo que indica un rendimiento poco satisfactorio en términos de clasificaciones correctas.
- Matriz de Confusión: En el primer modelo, hay un alto número de falsos negativos (11,090), lo cual significa que muchos fraudes no fueron detectados. Esto es crítico en un contexto de detección de fraude, donde es importante minimizar la cantidad de fraudes no detectados.
Recall: El recall del primer modelo para la clase de fraude es bajo, lo cual sugiere que no identifica correctamente los fraudes en una gran cantidad de casos. Esta deficiencia limita la utilidad del modelo en aplicaciones donde los falsos negativos pueden tener altos costos.
Modelo Mejorado:

- Precisión: 0.99, un rendimiento significativamente mejorado, lo que muestra que el modelo casi siempre clasifica correctamente ambas clases.
Matriz de Confusión: La reducción de falsos negativos a 0 y falsos positivos a 266 muestra que el modelo detecta casi todos los fraudes con una gran exactitud.
Recall y F1-Score: Ambos alcanzan 0.99 y 1.00 para la clase de fraude, lo que significa que el modelo no omite casos de fraude y mantiene una excelente precisión al clasificar.
Comparación Global:

- El segundo modelo supera claramente al primero en todas las métricas relevantes, especialmente en la detección de fraudes (FN = 0). Esto demuestra una mejora significativa en la precisión y confiabilidad para el objetivo final.
Conclusiones
- El primer modelo tiene un desempeño limitado, con un recall y precisión bajos en la clase de fraude. Esto muestra una capacidad insuficiente para detectar fraudes, con un alto riesgo de omitir casos de interés.
- El segundo modelo muestra un rendimiento excepcionalmente alto, lo que sugiere que las técnicas de balanceo y otros ajustes han ayudado a mejorar la capacidad del modelo para identificar fraudes con precisión.
Aunque el segundo modelo parece ser efectivo en términos de métricas, es importante considerar el contexto de producción y el potencial de generalización para evitar un sobreajuste a los datos de entrenamiento.


### Recomendaciones para Mejoras Futuras
Pruebas en Datos Reales:

- Evalúa el modelo en un conjunto de datos real o en datos de producción para confirmar que su rendimiento se mantenga. Esto es importante para asegurarse de que el modelo generaliza bien fuera del dataset balanceado de entrenamiento.
Pruebas de Robustez:

- Implementa técnicas de validación cruzada y utiliza métricas adicionales como el área bajo la curva ROC (AUC-ROC) para tener una mejor medida del rendimiento y evitar resultados sesgados.
Ingeniería de Características Adicionales:

- Analiza la posibilidad de incorporar nuevas características que puedan capturar mejor los patrones de fraude, como interacciones entre variables o estadísticas de transacciones.
Ajuste Fino de Modelos:

- Explora ajustes de hiperparámetros para el modelo, especialmente en el Random Forest y el Stacking Regressor, utilizando herramientas de optimización como GridSearchCV o RandomizedSearchCV para obtener los mejores resultados sin sobreajustar.
Experimentar con Técnicas Avanzadas de Balanceo:

- Aunque se obtuvo un buen resultado con el balanceo actual, puedes probar técnicas como ADASYN o BalancedBaggingClassifier para comparar y asegurar la estabilidad del modelo ante diferentes métodos de balanceo.
Al implementar estas recomendaciones, podrías obtener un modelo más robusto y confiable, especialmente en un entorno en el que los datos reales pueden ser considerablemente diferentes de los datos de entrenamiento.






